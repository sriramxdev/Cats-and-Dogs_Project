{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sriramxdev/Cats-and-Dogs_Project/blob/main/cats_and_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cba81e230b851b02"
      },
      "cell_type": "markdown",
      "source": [
        "# Image Classification of Cats and Dogs using CNN\n"
      ],
      "id": "cba81e230b851b02"
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4caae11a80ccd9e3",
        "outputId": "0b102e39-c5c5-42c5-b0bf-7877dd05d621"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "TensorFlow version: 2.18.0\n"
          ]
        }
      ],
      "execution_count": 2,
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model, save_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import time\n",
        "\n",
        "# Check if GPU is available\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ],
      "id": "4caae11a80ccd9e3"
    },
    {
      "metadata": {
        "id": "5789e771c12a85a2"
      },
      "cell_type": "markdown",
      "source": [
        "### Download and Prepare the Dataset"
      ],
      "id": "5789e771c12a85a2"
    },
    {
      "metadata": {
        "id": "94856f2c54fee15e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07558181-fb7f-4aa0-97a7-c530f7748321"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Download complete!\n",
            "Extracting dataset...\n",
            "Extraction complete!\n"
          ]
        }
      ],
      "execution_count": 3,
      "source": [
        "# Function to download and extract the dataset\n",
        "def download_and_extract_dataset():\n",
        "    # Create directories for the dataset\n",
        "    base_dir = 'dataset'\n",
        "    if not os.path.exists(base_dir):\n",
        "        os.makedirs(base_dir)\n",
        "\n",
        "    # URL for the dataset (Microsoft Cats and Dogs dataset)\n",
        "    url = 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip'\n",
        "\n",
        "    # Path to save the downloaded zip file\n",
        "    zip_path = os.path.join(base_dir, 'cats_and_dogs.zip')\n",
        "\n",
        "    # Download the dataset if it doesn't exist\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(\"Downloading dataset...\")\n",
        "        urllib.request.urlretrieve(url, zip_path)\n",
        "        print(\"Download complete!\")\n",
        "\n",
        "    # Extract the dataset if not already extracted\n",
        "    extract_dir = os.path.join(base_dir, 'PetImages')\n",
        "    if not os.path.exists(extract_dir):\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(base_dir)\n",
        "        print(\"Extraction complete!\")\n",
        "\n",
        "    return base_dir\n",
        "\n",
        "# Download and extract the dataset\n",
        "base_dir = download_and_extract_dataset()\n"
      ],
      "id": "94856f2c54fee15e"
    },
    {
      "metadata": {
        "id": "f69f3546ca168f00"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Organize the dataset into train, validation, and test sets\n",
        "def organize_dataset(base_dir):\n",
        "    # Create directories for train, validation, and test sets\n",
        "    train_dir = os.path.join(base_dir, 'train')\n",
        "    val_dir = os.path.join(base_dir, 'validation')\n",
        "    test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "    # Create subdirectories for cats and dogs in each set\n",
        "    for dir_path in [train_dir, val_dir, test_dir]:\n",
        "        if not os.path.exists(dir_path):\n",
        "            os.makedirs(dir_path)\n",
        "            os.makedirs(os.path.join(dir_path, 'cats'))\n",
        "            os.makedirs(os.path.join(dir_path, 'dogs'))\n",
        "\n",
        "    # If the dataset is already organized, return the directories\n",
        "    if len(os.listdir(os.path.join(train_dir, 'cats'))) > 0:\n",
        "        print(\"Dataset already organized.\")\n",
        "        return train_dir, val_dir, test_dir\n",
        "\n",
        "    # Source directories for cats and dogs\n",
        "    cats_dir = os.path.join(base_dir, 'PetImages', 'Cat')\n",
        "    dogs_dir = os.path.join(base_dir, 'PetImages', 'Dog')\n",
        "\n",
        "    # Function to remove corrupted images\n",
        "    def is_valid_image(file_path):\n",
        "        try:\n",
        "            img = cv2.imread(file_path)\n",
        "            return img is not None\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    # Get list of valid cat and dog images\n",
        "    cat_files = [f for f in os.listdir(cats_dir) if is_valid_image(os.path.join(cats_dir, f))]\n",
        "    dog_files = [f for f in os.listdir(dogs_dir) if is_valid_image(os.path.join(dogs_dir, f))]\n",
        "\n",
        "    # Shuffle the files\n",
        "    random.shuffle(cat_files)\n",
        "    random.shuffle(dog_files)\n",
        "\n",
        "    # Split the files into train (70%), validation (15%), and test (15%) sets\n",
        "    n_cats_train = int(0.7 * len(cat_files))\n",
        "    n_cats_val = int(0.15 * len(cat_files))\n",
        "\n",
        "    n_dogs_train = int(0.7 * len(dog_files))\n",
        "    n_dogs_val = int(0.15 * len(dog_files))\n",
        "\n",
        "    # Copy cat images to their respective directories\n",
        "    for i, file in enumerate(cat_files):\n",
        "        src = os.path.join(cats_dir, file)\n",
        "        if i < n_cats_train:\n",
        "            dst = os.path.join(train_dir, 'cats', file)\n",
        "        elif i < n_cats_train + n_cats_val:\n",
        "            dst = os.path.join(val_dir, 'cats', file)\n",
        "        else:\n",
        "            dst = os.path.join(test_dir, 'cats', file)\n",
        "        os.link(src, dst)  # Create hard link instead of copying to save space\n",
        "\n",
        "    # Copy dog images to their respective directories\n",
        "    for i, file in enumerate(dog_files):\n",
        "        src = os.path.join(dogs_dir, file)\n",
        "        if i < n_dogs_train:\n",
        "            dst = os.path.join(train_dir, 'dogs', file)\n",
        "        elif i < n_dogs_train + n_dogs_val:\n",
        "            dst = os.path.join(val_dir, 'dogs', file)\n",
        "        else:\n",
        "            dst = os.path.join(test_dir, 'dogs', file)\n",
        "        os.link(src, dst)  # Create hard link instead of copying to save space\n",
        "\n",
        "    print(f\"Dataset organized into:\\n\"\n",
        "          f\"- Train: {len(os.listdir(os.path.join(train_dir, 'cats')))} cats, {len(os.listdir(os.path.join(train_dir, 'dogs')))} dogs\\n\"\n",
        "          f\"- Validation: {len(os.listdir(os.path.join(val_dir, 'cats')))} cats, {len(os.listdir(os.path.join(val_dir, 'dogs')))} dogs\\n\"\n",
        "          f\"- Test: {len(os.listdir(os.path.join(test_dir, 'cats')))} cats, {len(os.listdir(os.path.join(test_dir, 'dogs')))} dogs\")\n",
        "\n",
        "    return train_dir, val_dir, test_dir\n",
        "\n",
        "# Organize the dataset\n",
        "train_dir, val_dir, test_dir = organize_dataset(base_dir)\n"
      ],
      "id": "f69f3546ca168f00"
    },
    {
      "metadata": {
        "id": "b05764e4ee43a386"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Visualization\n"
      ],
      "id": "b05764e4ee43a386"
    },
    {
      "metadata": {
        "id": "7bf14908d2255d4c"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Function to display random images from the dataset\n",
        "def display_random_images(directory, n=5):\n",
        "    cats_dir = os.path.join(directory, 'cats')\n",
        "    dogs_dir = os.path.join(directory, 'dogs')\n",
        "\n",
        "    cat_files = random.sample(os.listdir(cats_dir), n)\n",
        "    dog_files = random.sample(os.listdir(dogs_dir), n)\n",
        "\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    # Display cat images\n",
        "    for i, file in enumerate(cat_files):\n",
        "        img_path = os.path.join(cats_dir, file)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
        "\n",
        "        plt.subplot(2, n, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'Cat {i+1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "    # Display dog images\n",
        "    for i, file in enumerate(dog_files):\n",
        "        img_path = os.path.join(dogs_dir, file)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
        "\n",
        "        plt.subplot(2, n, n+i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'Dog {i+1}')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display random images from the training set\n",
        "display_random_images(train_dir)\n"
      ],
      "id": "7bf14908d2255d4c"
    },
    {
      "metadata": {
        "id": "ebb7fd1e95de6b83"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Data Preprocessing and Augmentation"
      ],
      "id": "ebb7fd1e95de6b83"
    },
    {
      "metadata": {
        "id": "676bc21b02fa6b3e"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Define image dimensions and batch size\n",
        "IMG_WIDTH = 150\n",
        "IMG_HEIGHT = 150\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Create data generators with augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Create data generators without augmentation for validation and test\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create generators for training, validation, and test sets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "id": "676bc21b02fa6b3e"
    },
    {
      "metadata": {
        "id": "411df3131c53eeb8"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualization"
      ],
      "id": "411df3131c53eeb8"
    },
    {
      "metadata": {
        "id": "1651cef1e5fdd4b"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Function to display augmented images\n",
        "def display_augmented_images():\n",
        "    # Get a batch of images from the training generator\n",
        "    x_batch, y_batch = next(train_generator)\n",
        "\n",
        "    # Display 5 augmented images\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    for i in range(5):\n",
        "        plt.subplot(1, 5, i+1)\n",
        "        plt.imshow(x_batch[i])\n",
        "        plt.title('Cat' if y_batch[i] == 0 else 'Dog')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display augmented images\n",
        "display_augmented_images()\n"
      ],
      "id": "1651cef1e5fdd4b"
    },
    {
      "metadata": {
        "id": "a85c7b47e184cdfd"
      },
      "cell_type": "markdown",
      "source": [
        "### Build the CNN Model\n"
      ],
      "id": "a85c7b47e184cdfd"
    },
    {
      "metadata": {
        "id": "111e73d6a5bc871e"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Function to create the CNN model\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        # First convolutional block\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "        MaxPooling2D(2, 2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        # Second convolutional block\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        # Third convolutional block\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        # Fourth convolutional block\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        # Flatten the output and add dense layers\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),  # Add dropout to prevent overfitting\n",
        "        Dense(1, activation='sigmoid')  # Binary classification (cat or dog)\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0005),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = create_model()\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "id": "111e73d6a5bc871e"
    },
    {
      "metadata": {
        "id": "1e15d0af5af17eee"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the Model"
      ],
      "id": "1e15d0af5af17eee"
    },
    {
      "metadata": {
        "id": "88821f685cf82999"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Create callbacks for training\n",
        "callbacks = [\n",
        "    # Stop training when validation loss stops improving\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "\n",
        "    # Save the best model during training\n",
        "    ModelCheckpoint('models/cats_dogs_model.h5', monitor='val_accuracy', save_best_only=True, mode='max'),\n",
        "\n",
        "    # Reduce learning rate when validation loss plateaus\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "]\n",
        "\n",
        "# Calculate steps per epoch and validation steps\n",
        "steps_per_epoch = train_generator.samples // BATCH_SIZE\n",
        "validation_steps = validation_generator.samples // BATCH_SIZE\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "id": "88821f685cf82999"
    },
    {
      "metadata": {
        "id": "bea518eb5a5b34"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation"
      ],
      "id": "bea518eb5a5b34"
    },
    {
      "metadata": {
        "id": "a22186e3f002cf54"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Plot training and validation accuracy and loss\n",
        "def plot_training_history(history):\n",
        "    # Plot accuracy\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the training history\n",
        "plot_training_history(history)\n"
      ],
      "id": "a22186e3f002cf54"
    },
    {
      "metadata": {
        "id": "968cdfc8296b355c"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n"
      ],
      "id": "968cdfc8296b355c"
    },
    {
      "metadata": {
        "id": "8c1b912ff444b8cf"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Generate predictions for the test set\n",
        "test_generator.reset()\n",
        "predictions = model.predict(test_generator, steps=test_generator.samples // BATCH_SIZE + 1)\n",
        "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "# Get the true labels\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(true_classes, predicted_classes, target_names=['Cat', 'Dog']))\n"
      ],
      "id": "8c1b912ff444b8cf"
    },
    {
      "metadata": {
        "id": "8b6562f16461095f"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize Model Predictions\n"
      ],
      "id": "8b6562f16461095f"
    },
    {
      "metadata": {
        "id": "b12a3dc3bf158272"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Function to display random test images with predictions\n",
        "def display_predictions(n=5):\n",
        "    # Reset the test generator\n",
        "    test_generator.reset()\n",
        "\n",
        "    # Get a batch of test images\n",
        "    x_batch, y_batch = next(test_generator)\n",
        "\n",
        "    # Make predictions on the batch\n",
        "    predictions = model.predict(x_batch)\n",
        "\n",
        "    # Display images with predictions\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(x_batch[i])\n",
        "\n",
        "        # Get the true and predicted labels\n",
        "        true_label = 'Cat' if y_batch[i] == 0 else 'Dog'\n",
        "        pred_label = 'Cat' if predictions[i][0] < 0.5 else 'Dog'\n",
        "        confidence = predictions[i][0] if pred_label == 'Dog' else 1 - predictions[i][0]\n",
        "\n",
        "        # Set the title color based on whether the prediction is correct\n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "\n",
        "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.2f}\", color=color)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display predictions on random test images\n",
        "display_predictions()\n"
      ],
      "id": "b12a3dc3bf158272"
    },
    {
      "metadata": {
        "id": "33266ace1a51a15e"
      },
      "cell_type": "markdown",
      "source": [
        "### Save the Model\n"
      ],
      "id": "33266ace1a51a15e"
    },
    {
      "metadata": {
        "id": "15abdae7ac65ae0e"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Create the models directory if it doesn't exist\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "\n",
        "# Save the model in HDF5 format\n",
        "model.save('models/cats_dogs_model.h5')\n",
        "print(\"Model saved in HDF5 format.\")\n",
        "\n",
        "# Save the model in SavedModel format (TensorFlow's recommended format)\n",
        "model.save('models/cats_dogs_savedmodel.keras')\n",
        "print(\"Model saved in SavedModel format.\")\n"
      ],
      "id": "15abdae7ac65ae0e"
    },
    {
      "metadata": {
        "id": "90f95efe630d4e46"
      },
      "cell_type": "markdown",
      "source": [
        "### Test the Saved Model\n"
      ],
      "id": "90f95efe630d4e46"
    },
    {
      "metadata": {
        "id": "aa29e8c797dc3073"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# Load the saved model\n",
        "loaded_model = load_model('models/cats_dogs_model.h5')\n",
        "\n",
        "# Evaluate the loaded model on the test set\n",
        "test_generator.reset()\n",
        "test_loss, test_accuracy = loaded_model.evaluate(test_generator)\n",
        "print(f\"Loaded Model Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Loaded Model Test Loss: {test_loss:.4f}\")\n"
      ],
      "id": "aa29e8c797dc3073"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}